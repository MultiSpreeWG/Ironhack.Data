{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import pymysql and sqlalchemy as you have learnt in the lesson of importing/exporting data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a mysql engine to set the connection to the server. Check the connection details in [this link](https://relational.fit.cvut.cz/search?tableCount%5B%5D=0-10&tableCount%5B%5D=10-30&dataType%5B%5D=Numeric&databaseSize%5B%5D=KB&databaseSize%5B%5D=MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(mysql+pymysql://guest:***@relational.fit.cvut.cz)\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\"mysql+pymysql://guest:relational@relational.fit.cvut.cz\")\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Import the users table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_sql_query(\"SELECT * FROM stats.users\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Rename Id column to userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.rename(columns = {\"Id\": \"userId\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Import the posts table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_sql_query(\"SELECT * FROM stats.posts\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Id column to postId and OwnerUserId to userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       postId  PostTypeId  AcceptedAnswerId         CreaionDate  Score  \\\n",
      "0           1           1              15.0 2010-07-19 19:12:12     23   \n",
      "1           2           1              59.0 2010-07-19 19:12:57     22   \n",
      "2           3           1               5.0 2010-07-19 19:13:28     54   \n",
      "3           4           1             135.0 2010-07-19 19:13:31     13   \n",
      "4           5           2               NaN 2010-07-19 19:14:43     81   \n",
      "5           6           1               NaN 2010-07-19 19:14:44    152   \n",
      "6           7           1              18.0 2010-07-19 19:15:59     76   \n",
      "7           8           1               NaN 2010-07-19 19:16:21      0   \n",
      "8           9           2               NaN 2010-07-19 19:16:27     13   \n",
      "9          10           1            1887.0 2010-07-19 19:17:47     23   \n",
      "10         11           1            1201.0 2010-07-19 19:18:30      2   \n",
      "11         12           2               NaN 2010-07-19 19:18:41     20   \n",
      "12         13           2               NaN 2010-07-19 19:18:56     14   \n",
      "13         14           2               NaN 2010-07-19 19:19:03      5   \n",
      "14         15           2               NaN 2010-07-19 19:19:46     13   \n",
      "15         16           2               NaN 2010-07-19 19:22:31     16   \n",
      "16         17           1              29.0 2010-07-19 19:24:12      9   \n",
      "17         18           2               NaN 2010-07-19 19:24:18     31   \n",
      "18         19           2               NaN 2010-07-19 19:24:21     12   \n",
      "19         20           2               NaN 2010-07-19 19:24:35      3   \n",
      "20         21           1               NaN 2010-07-19 19:24:36      4   \n",
      "21         22           1               NaN 2010-07-19 19:25:39    102   \n",
      "22         23           1              91.0 2010-07-19 19:26:04     10   \n",
      "23         24           2               NaN 2010-07-19 19:26:13     17   \n",
      "24         25           1              32.0 2010-07-19 19:27:13      7   \n",
      "25         26           1              61.0 2010-07-19 19:27:43     18   \n",
      "26         27           2               NaN 2010-07-19 19:28:12      4   \n",
      "27         28           2               NaN 2010-07-19 19:28:12      6   \n",
      "28         29           2               NaN 2010-07-19 19:28:15      5   \n",
      "29         30           1              55.0 2010-07-19 19:28:34      7   \n",
      "...       ...         ...               ...                 ...    ...   \n",
      "91946  115346           2               NaN 2014-09-13 13:15:18      0   \n",
      "91947  115348           1               NaN 2014-09-13 15:17:03      0   \n",
      "91948  115350           1               NaN 2014-09-13 15:26:01      0   \n",
      "91949  115351           1               NaN 2014-09-13 15:32:18      1   \n",
      "91950  115352           1               NaN 2014-09-13 15:56:55      0   \n",
      "91951  115353           2               NaN 2014-09-13 16:15:30      0   \n",
      "91952  115354           2               NaN 2014-09-13 16:25:32      2   \n",
      "91953  115355           1               NaN 2014-09-13 16:30:00      3   \n",
      "91954  115356           1               NaN 2014-09-13 16:34:58      1   \n",
      "91955  115357           2               NaN 2014-09-13 17:07:54      1   \n",
      "91956  115358           1               NaN 2014-09-13 17:29:23      2   \n",
      "91957  115360           1               NaN 2014-09-13 18:06:50      2   \n",
      "91958  115361           1               NaN 2014-09-13 18:36:36      0   \n",
      "91959  115362           2               NaN 2014-09-13 18:44:31      2   \n",
      "91960  115363           2               NaN 2014-09-13 19:37:20      0   \n",
      "91961  115364           1               NaN 2014-09-13 19:50:17      0   \n",
      "91962  115365           2               NaN 2014-09-13 20:13:11     -1   \n",
      "91963  115366           1               NaN 2014-09-13 20:36:55      1   \n",
      "91964  115367           1               NaN 2014-09-13 20:57:24      1   \n",
      "91965  115368           2               NaN 2014-09-13 21:01:39      4   \n",
      "91966  115369           2               NaN 2014-09-13 21:27:49      4   \n",
      "91967  115370           1               NaN 2014-09-13 21:39:30      1   \n",
      "91968  115371           1               NaN 2014-09-13 21:55:39      0   \n",
      "91969  115372           2               NaN 2014-09-13 23:15:00      0   \n",
      "91970  115373           2               NaN 2014-09-13 23:18:30      0   \n",
      "91971  115374           2               NaN 2014-09-13 23:45:39      2   \n",
      "91972  115375           1               NaN 2014-09-13 23:46:05      0   \n",
      "91973  115376           1               NaN 2014-09-14 01:27:54      1   \n",
      "91974  115377           2               NaN 2014-09-14 02:03:28      0   \n",
      "91975  115378           2               NaN 2014-09-14 02:09:23      0   \n",
      "\n",
      "       ViewCount                                               Body   userId  \\\n",
      "0         1278.0  <p>How should I elicit prior distributions fro...      8.0   \n",
      "1         8198.0  <p>In many different statistical methods there...     24.0   \n",
      "2         3613.0  <p>What are some valuable Statistical Analysis...     18.0   \n",
      "3         5224.0  <p>I have two groups of data.  Each with a dif...     23.0   \n",
      "4            NaN  <p>The R-project</p>\\n\\n<p><a href=\"http://www...     23.0   \n",
      "5        29229.0  <p>Last year, I read a blog post from <a href=...      5.0   \n",
      "6         5808.0  <p>I've been working on a new method for analy...     38.0   \n",
      "7          288.0  <p>Sorry, but the emptyness was a bit overwhel...     37.0   \n",
      "8            NaN  <p><a href=\"http://incanter.org/\">Incanter</a>...     50.0   \n",
      "9        21925.0  <p>Many studies in the social sciences use Lik...     24.0   \n",
      "10         224.0  <p>Is there a good, modern treatment covering ...     34.0   \n",
      "11           NaN  <p>See my response to <a href=\"http://stackove...      5.0   \n",
      "12           NaN  <p>Machine Learning seems to have its basis in...     23.0   \n",
      "13           NaN  <p>I second that Jay. Why is R valuable? Here'...     36.0   \n",
      "14           NaN  <p>John Cook gives some interesting recommenda...      6.0   \n",
      "15           NaN  <p>Two projects spring to mind:</p>\\n\\n<ol>\\n<...      8.0   \n",
      "16        1261.0  <p>I have four competing models which I use to...      NaN   \n",
      "17           NaN  <p>Also see the UCI machine learning Data Repo...     36.0   \n",
      "18           NaN  <p><a href=\"http://www.gapminder.org/data/\">Ga...     55.0   \n",
      "19           NaN  <p>The assumption of normality assumes your da...     37.0   \n",
      "20         184.0  <p>What are some of the ways to forecast demog...     59.0   \n",
      "21       21916.0  <p>How would you describe in plain English the...     66.0   \n",
      "22        7694.0  <p>How can I find the PDF (probability density...     69.0   \n",
      "23           NaN  <p>For doing a variety of MCMC tasks in Python...     61.0   \n",
      "24        2095.0  <p>What modern tools (Windows-based) do you su...     69.0   \n",
      "25        3476.0  <p>What is a standard deviation, how is it cal...     75.0   \n",
      "26           NaN  <p><a href=\"http://mathforum.org/workshops/sum...     68.0   \n",
      "27           NaN  <p><a href=\"http://www.gnu.org/software/gsl/\" ...      NaN   \n",
      "28           NaN  <p>Contingency table (chi-square). Also Logist...     36.0   \n",
      "29         705.0  <p>Which methods are used for testing random v...     69.0   \n",
      "...          ...                                                ...      ...   \n",
      "91946        NaN  <p>First, let's try to simulate some data with...  42434.0   \n",
      "91947       18.0  <p>In the game of Bridge, 52 cards are distrub...  55564.0   \n",
      "91948        3.0  <p>How do we specify negative costs in rpart? ...  55731.0   \n",
      "91949        9.0  <p>If one is conducting a survey in which all ...   7331.0   \n",
      "91950       16.0  <p>For example, I was looking at <a href=\"http...  55734.0   \n",
      "91951        NaN  <p>I have strong reservations about whether me...   7290.0   \n",
      "91952        NaN  <p>If all the null hypotheses were true, 5% of...    805.0   \n",
      "91953       49.0  <p>I have a methodological question, and there...  35413.0   \n",
      "91954       15.0  <p>I'm a beginner in statistics and I have to ...  55733.0   \n",
      "91955        NaN  <p>I've personally been asking this question f...  44142.0   \n",
      "91956       15.0  <p>Are there any formulae for the quantiles of...   1569.0   \n",
      "91957       40.0  <p>Is Student's t test a Wald test?</p>\\n\\n<p>...  55738.0   \n",
      "91958       12.0  <p>Given the biometric match scores, I am requ...  55383.0   \n",
      "91959        NaN  <p>Theoretical insight, institutional knowledg...   7071.0   \n",
      "91960        NaN  <p>I think I got a very simple answer.</p>\\n\\n...   2676.0   \n",
      "91961       11.0  <p>I'm trying to find the most similar sample ...  52858.0   \n",
      "91962        NaN  <blockquote>\\n  <p>Is there some approach to u...  28236.0   \n",
      "91963       17.0  <p>Does any standard statistical software like...  55742.0   \n",
      "91964       97.0  <p>Jon and Frank ordered 2 footlong sandwiches...  41961.0   \n",
      "91965        NaN  <p>You need to multiply the probabilities with...  24808.0   \n",
      "91966        NaN  <p>Line up the four sandwiches in a row where ...   6633.0   \n",
      "91967       13.0  <p>im analyzing an article for my studies with...  55744.0   \n",
      "91968       19.0  <p>I am trying to estimate the school effects ...  35801.0   \n",
      "91969        NaN  <p>If prior to running the xtreg command you h...  48579.0   \n",
      "91970        NaN  <p>Yes, the <a href=\"http://cran.r-project.org...  48579.0   \n",
      "91971        NaN  <p>This grew too long for a comment, but I thi...    805.0   \n",
      "91972        9.0  <p>Assume a classification problem where there...  49365.0   \n",
      "91973        5.0  <p>My goal is to create a formula that can giv...  55746.0   \n",
      "91974        NaN  <p>As a practical answer to the real questions...    805.0   \n",
      "91975        NaN  <p>Decision trees are notoriously <strong>unst...   7250.0   \n",
      "\n",
      "          LasActivityDate                                              Title  \\\n",
      "0     2010-09-15 21:08:26                      Eliciting priors from experts   \n",
      "1     2012-11-12 09:21:54                                 What is normality?   \n",
      "2     2013-05-27 14:48:36  What are some valuable Statistical Analysis op...   \n",
      "3     2010-09-08 03:00:19  Assessing the significance of differences in d...   \n",
      "4     2010-07-19 19:21:15                                               None   \n",
      "5     2014-05-29 03:54:31  The Two Cultures: statistics vs. machine learn...   \n",
      "6     2013-12-28 06:53:10             Locating freely available data samples   \n",
      "7     2010-10-18 07:57:31  So how many staticians *does* it take to screw...   \n",
      "8     2010-07-19 19:16:27                                               None   \n",
      "9     2012-10-23 17:33:41  Under what conditions should Likert scales be ...   \n",
      "10    2010-08-03 21:50:09              Multivariate Interpolation Approaches   \n",
      "11    2010-07-19 19:18:41                                               None   \n",
      "12    2010-07-19 19:18:56                                               None   \n",
      "13    2010-07-19 19:19:03                                               None   \n",
      "14    2010-07-19 19:19:46                                               None   \n",
      "15    2010-07-19 20:43:02                                               None   \n",
      "16    2012-01-22 23:34:51             How can I adapt ANOVA for binary data?   \n",
      "17    2010-07-19 19:24:18                                               None   \n",
      "18    2010-07-19 19:24:21                                               None   \n",
      "19    2010-07-19 19:24:35                                               None   \n",
      "20    2010-09-30 21:14:45                     Forecasting demographic census   \n",
      "21    2014-06-05 02:06:32  Bayesian and frequentist reasoning in plain En...   \n",
      "22    2010-07-20 08:52:27                      Finding the PDF given the CDF   \n",
      "23    2010-07-19 19:26:13                                               None   \n",
      "24    2014-08-13 20:29:48           Tools for modeling financial time series   \n",
      "25    2013-07-30 10:19:04                      What is a standard deviation?   \n",
      "26    2010-07-19 19:28:12                                               None   \n",
      "27    2010-07-19 19:28:12                                               None   \n",
      "28    2010-07-19 19:28:15                                               None   \n",
      "29    2011-05-12 18:38:27       Testing random variate generation algorithms   \n",
      "...                   ...                                                ...   \n",
      "91946 2014-09-13 13:15:18                                               None   \n",
      "91947 2014-09-13 16:25:32  Please help me interpret this goodness of fit ...   \n",
      "91948 2014-09-13 15:26:01  Specifying negative costs (benefits) in rpart'...   \n",
      "91949 2014-09-13 15:43:23               Sampling frame of a voluntary survey   \n",
      "91950 2014-09-13 16:15:30  Is there a way to estimate the distribution fr...   \n",
      "91951 2014-09-13 16:15:30                                               None   \n",
      "91952 2014-09-13 16:25:32                                               None   \n",
      "91953 2014-09-13 18:53:58  Adjust for everything you have in propensity s...   \n",
      "91954 2014-09-13 20:45:45  How to interpret glmer results (variance, corr...   \n",
      "91955 2014-09-13 17:07:54                                               None   \n",
      "91956 2014-09-14 02:54:13  Quantiles of a compound gamma/negative binomia...   \n",
      "91957 2014-09-13 18:06:50                   Is Student's t test a Wald test?   \n",
      "91958 2014-09-13 18:36:36            Plotting of density estimates in matlab   \n",
      "91959 2014-09-13 18:53:58                                               None   \n",
      "91960 2014-09-13 19:37:20                                               None   \n",
      "91961 2014-09-13 21:30:41          In search of a proper similarity function   \n",
      "91962 2014-09-13 20:13:11                                               None   \n",
      "91963 2014-09-13 23:18:30                     Missing data analysis software   \n",
      "91964 2014-09-14 02:05:41  How to add odds? (or how I got the wrong sandw...   \n",
      "91965 2014-09-13 21:01:39                                               None   \n",
      "91966 2014-09-13 21:27:49                                               None   \n",
      "91967 2014-09-13 21:39:30                                 Poisson regression   \n",
      "91968 2014-09-13 23:15:00  Estimation of school effects using xtmixed (in...   \n",
      "91969 2014-09-13 23:15:00                                               None   \n",
      "91970 2014-09-13 23:18:30                                               None   \n",
      "91971 2014-09-14 02:05:41                                               None   \n",
      "91972 2014-09-14 02:09:23  Detecting a consistent pattern in a dataset vi...   \n",
      "91973 2014-09-14 01:40:55  How to project video viewcount based on histor...   \n",
      "91974 2014-09-14 02:54:13                                               None   \n",
      "91975 2014-09-14 02:09:23                                               None   \n",
      "\n",
      "       ... AnswerCount  CommentCount  postId  LastEditorUserId  \\\n",
      "0      ...         5.0             1    14.0               NaN   \n",
      "1      ...         7.0             1     8.0              88.0   \n",
      "2      ...        19.0             4    36.0             183.0   \n",
      "3      ...         5.0             2     2.0               NaN   \n",
      "4      ...         NaN             3     NaN              23.0   \n",
      "5      ...        15.0             5   137.0           22047.0   \n",
      "6      ...        24.0             3    79.0             253.0   \n",
      "7      ...         1.0             2     NaN             449.0   \n",
      "8      ...         NaN             3     NaN               NaN   \n",
      "9      ...         4.0             4    12.0             919.0   \n",
      "10     ...         1.0             2     1.0              34.0   \n",
      "11     ...         NaN             1     NaN               NaN   \n",
      "12     ...         NaN             4     NaN               NaN   \n",
      "13     ...         NaN             1     NaN               NaN   \n",
      "14     ...         NaN             0     NaN               NaN   \n",
      "15     ...         NaN             3     NaN               8.0   \n",
      "16     ...         1.0             0     1.0            7972.0   \n",
      "17     ...         NaN             1     NaN               NaN   \n",
      "18     ...         NaN             0     NaN               NaN   \n",
      "19     ...         NaN             2     NaN               NaN   \n",
      "20     ...         1.0             1     1.0             930.0   \n",
      "21     ...        15.0             1    67.0             930.0   \n",
      "22     ...         2.0             1     2.0               NaN   \n",
      "23     ...         NaN             0     NaN               NaN   \n",
      "24     ...         7.0             4     5.0              69.0   \n",
      "25     ...         8.0            14     7.0           22047.0   \n",
      "26     ...         NaN             0     NaN               NaN   \n",
      "27     ...         NaN             0     NaN               NaN   \n",
      "28     ...         NaN             0     NaN               NaN   \n",
      "29     ...         8.0             2     7.0             919.0   \n",
      "...    ...         ...           ...     ...               ...   \n",
      "91946  ...         NaN             0     NaN               NaN   \n",
      "91947  ...         1.0             3     NaN           55564.0   \n",
      "91948  ...         0.0             0     NaN               NaN   \n",
      "91949  ...         0.0             0     NaN            7290.0   \n",
      "91950  ...         1.0             0     NaN               NaN   \n",
      "91951  ...         NaN             0     NaN               NaN   \n",
      "91952  ...         NaN             0     NaN               NaN   \n",
      "91953  ...         2.0             0     NaN               NaN   \n",
      "91954  ...         0.0             0     NaN           55733.0   \n",
      "91955  ...         NaN             0     NaN               NaN   \n",
      "91956  ...         1.0             0     NaN               NaN   \n",
      "91957  ...         0.0             4     NaN               NaN   \n",
      "91958  ...         0.0             1     NaN               NaN   \n",
      "91959  ...         NaN             0     NaN            7071.0   \n",
      "91960  ...         NaN             0     NaN               NaN   \n",
      "91961  ...         0.0             3     NaN           52858.0   \n",
      "91962  ...         NaN             1     NaN               NaN   \n",
      "91963  ...         1.0             0     1.0               NaN   \n",
      "91964  ...         3.0             0     NaN             919.0   \n",
      "91965  ...         NaN             0     NaN               NaN   \n",
      "91966  ...         NaN             0     NaN               NaN   \n",
      "91967  ...         0.0             2     NaN               NaN   \n",
      "91968  ...         1.0             0     NaN           35801.0   \n",
      "91969  ...         NaN             9     NaN               NaN   \n",
      "91970  ...         NaN             0     NaN               NaN   \n",
      "91971  ...         NaN             2     NaN             805.0   \n",
      "91972  ...         1.0             0     NaN               NaN   \n",
      "91973  ...         0.0             2     NaN            7290.0   \n",
      "91974  ...         NaN             0     NaN             805.0   \n",
      "91975  ...         NaN             0     NaN               NaN   \n",
      "\n",
      "             LastEditDate  CommunityOwnedDate  ParentId          ClosedDate  \\\n",
      "0                     NaT                 NaT       NaN                 NaT   \n",
      "1     2010-08-07 17:56:44                 NaT       NaN                 NaT   \n",
      "2     2011-02-12 05:50:03 2010-07-19 19:13:28       NaN                 NaT   \n",
      "3                     NaT                 NaT       NaN                 NaT   \n",
      "4     2010-07-19 19:21:15 2010-07-19 19:14:43       3.0                 NaT   \n",
      "5     2013-06-07 06:38:10 2010-08-09 13:05:50       NaN                 NaT   \n",
      "6     2013-09-26 21:50:36 2010-07-20 20:50:48       NaN                 NaT   \n",
      "7     2010-10-18 07:57:31                 NaT       NaN 2010-07-19 20:19:46   \n",
      "8                     NaT 2010-07-19 19:16:27       3.0                 NaT   \n",
      "9     2011-03-30 15:31:46                 NaT       NaN                 NaT   \n",
      "10    2010-07-28 07:58:52                 NaT       NaN                 NaT   \n",
      "11                    NaT 2011-08-12 20:29:33       7.0                 NaT   \n",
      "12                    NaT                 NaT       6.0                 NaT   \n",
      "13                    NaT 2010-07-19 19:19:03       3.0                 NaT   \n",
      "14                    NaT                 NaT       1.0                 NaT   \n",
      "15    2010-07-19 20:43:02 2010-07-19 19:22:31       3.0                 NaT   \n",
      "16    2012-01-22 23:34:51                 NaT       NaN                 NaT   \n",
      "17                    NaT 2011-08-12 20:31:32       7.0                 NaT   \n",
      "18                    NaT 2011-08-12 20:29:45       7.0                 NaT   \n",
      "19                    NaT                 NaT       2.0                 NaT   \n",
      "20    2010-09-30 21:14:45                 NaT       NaN                 NaT   \n",
      "21    2011-10-04 07:05:14                 NaT       NaN                 NaT   \n",
      "22                    NaT                 NaT       NaN                 NaT   \n",
      "23                    NaT 2010-07-19 19:26:13       3.0                 NaT   \n",
      "24    2010-07-26 23:38:29 2010-07-26 23:38:29       NaN                 NaT   \n",
      "25    2013-07-30 10:19:04                 NaT       NaN                 NaT   \n",
      "26                    NaT 2011-08-12 20:29:55       7.0                 NaT   \n",
      "27                    NaT 2010-07-19 19:28:12       3.0                 NaT   \n",
      "28                    NaT                 NaT      17.0                 NaT   \n",
      "29    2010-08-25 14:12:54                 NaT       NaN                 NaT   \n",
      "...                   ...                 ...       ...                 ...   \n",
      "91946                 NaT                 NaT  113980.0                 NaT   \n",
      "91947 2014-09-13 15:41:36                 NaT       NaN                 NaT   \n",
      "91948                 NaT                 NaT       NaN                 NaT   \n",
      "91949 2014-09-13 15:43:23                 NaT       NaN                 NaT   \n",
      "91950                 NaT                 NaT       NaN                 NaT   \n",
      "91951                 NaT                 NaT  115352.0                 NaT   \n",
      "91952                 NaT                 NaT  115348.0                 NaT   \n",
      "91953                 NaT                 NaT       NaN                 NaT   \n",
      "91954 2014-09-13 20:45:45                 NaT       NaN                 NaT   \n",
      "91955                 NaT                 NaT  115355.0                 NaT   \n",
      "91956                 NaT                 NaT       NaN                 NaT   \n",
      "91957                 NaT                 NaT       NaN                 NaT   \n",
      "91958                 NaT                 NaT       NaN                 NaT   \n",
      "91959 2014-09-13 18:53:58                 NaT  115355.0                 NaT   \n",
      "91960                 NaT                 NaT  115279.0                 NaT   \n",
      "91961 2014-09-13 21:30:41                 NaT       NaN                 NaT   \n",
      "91962                 NaT                 NaT  108430.0                 NaT   \n",
      "91963                 NaT                 NaT       NaN                 NaT   \n",
      "91964 2014-09-13 21:11:36                 NaT       NaN                 NaT   \n",
      "91965                 NaT                 NaT  115367.0                 NaT   \n",
      "91966                 NaT                 NaT  115367.0                 NaT   \n",
      "91967                 NaT                 NaT       NaN                 NaT   \n",
      "91968 2014-09-13 22:51:35                 NaT       NaN                 NaT   \n",
      "91969                 NaT                 NaT  115371.0                 NaT   \n",
      "91970                 NaT                 NaT  115366.0                 NaT   \n",
      "91971 2014-09-14 02:05:41                 NaT  115367.0                 NaT   \n",
      "91972                 NaT                 NaT       NaN                 NaT   \n",
      "91973 2014-09-14 01:40:55                 NaT       NaN                 NaT   \n",
      "91974 2014-09-14 02:54:13                 NaT  115358.0                 NaT   \n",
      "91975                 NaT                 NaT  115375.0                 NaT   \n",
      "\n",
      "      OwnerDisplayName LastEditorDisplayName  \n",
      "0                 None                  None  \n",
      "1                 None                  None  \n",
      "2                 None                  None  \n",
      "3                 None                  None  \n",
      "4                 None                  None  \n",
      "5                 None                  None  \n",
      "6                 None                  None  \n",
      "7                 None                  None  \n",
      "8                 None                  None  \n",
      "9                 None                  None  \n",
      "10                None                  None  \n",
      "11                None                  None  \n",
      "12                None                  None  \n",
      "13                None                  None  \n",
      "14                None                  None  \n",
      "15                None                  None  \n",
      "16              user28                  None  \n",
      "17                None                  None  \n",
      "18                None                  None  \n",
      "19                None                  None  \n",
      "20                None                  None  \n",
      "21                None                  None  \n",
      "22                None                  None  \n",
      "23                None                  None  \n",
      "24                None                  None  \n",
      "25                None                  None  \n",
      "26                None                  None  \n",
      "27              user28                  None  \n",
      "28                None                  None  \n",
      "29                None                  None  \n",
      "...                ...                   ...  \n",
      "91946             None                  None  \n",
      "91947             None                  None  \n",
      "91948             None                  None  \n",
      "91949             None                  None  \n",
      "91950             None                  None  \n",
      "91951             None                  None  \n",
      "91952             None                  None  \n",
      "91953             None                  None  \n",
      "91954             None                  None  \n",
      "91955             None                  None  \n",
      "91956             None                  None  \n",
      "91957             None                  None  \n",
      "91958             None                  None  \n",
      "91959             None                  None  \n",
      "91960             None                  None  \n",
      "91961             None                  None  \n",
      "91962             None                  None  \n",
      "91963             None                  None  \n",
      "91964             None                  None  \n",
      "91965             None                  None  \n",
      "91966             None                  None  \n",
      "91967             None                  None  \n",
      "91968             None                  None  \n",
      "91969             None                  None  \n",
      "91970             None                  None  \n",
      "91971             None                  None  \n",
      "91972             None                  None  \n",
      "91973             None                  None  \n",
      "91974             None                  None  \n",
      "91975             None                  None  \n",
      "\n",
      "[91976 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "posts = posts.rename(columns = {\"OwnerUserId\" : \"userId\"})\n",
    "posts = posts.rename(columns = {\"Id\" : \"postId\"})\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Define new dataframes for users and posts with the following selected columns:\n",
    "    **users columns**: userId, Reputation,Views,UpVotes,DownVotes\n",
    "    **posts columns**: postId, Score,userID,ViewCount,CommentCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  Reputation  Views  UpVotes  DownVotes\n",
      "0      -1           1      0     5007       1920\n",
      "1       2         101     25        3          0\n",
      "2       3         101     22       19          0\n",
      "3       4         101     11        0          0\n",
      "4       5        6792   1145      662          5\n",
      "   postId  postId  Score  userId  ViewCount  CommentCount\n",
      "0       1    14.0     23     8.0     1278.0             1\n",
      "1       2     8.0     22    24.0     8198.0             1\n",
      "2       3    36.0     54    18.0     3613.0             4\n",
      "3       4     2.0     13    23.0     5224.0             2\n",
      "4       5     NaN     81    23.0        NaN             3\n"
     ]
    }
   ],
   "source": [
    "users2 = users[[\"userId\", \"Reputation\",\"Views\",\"UpVotes\",\"DownVotes\"]]\n",
    "print(users2.head())\n",
    "posts2 = posts[[\"postId\",\"Score\",\"userId\",\"ViewCount\",\"CommentCount\"]]\n",
    "print(posts2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Merge both dataframes, users and posts. \n",
    "You will need to make a [merge](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) of posts and users dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merge = posts.merge(users, on=\"userId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. How many missing values do you have in your merged dataframe? On which columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 90584 entries, 0 to 90583\n",
      "Data columns (total 34 columns):\n",
      "postId                   90584 non-null int64\n",
      "PostTypeId               90584 non-null int64\n",
      "AcceptedAnswerId         14563 non-null float64\n",
      "CreaionDate              90584 non-null datetime64[ns]\n",
      "Score                    90584 non-null int64\n",
      "ViewCount                42188 non-null float64\n",
      "Body                     90364 non-null object\n",
      "userId                   90584 non-null float64\n",
      "LasActivityDate          90584 non-null datetime64[ns]\n",
      "Title                    42188 non-null object\n",
      "Tags                     42188 non-null object\n",
      "AnswerCount              42188 non-null float64\n",
      "CommentCount             90584 non-null int64\n",
      "postId                   12979 non-null float64\n",
      "LastEditorUserId         44128 non-null float64\n",
      "LastEditDate             44356 non-null datetime64[ns]\n",
      "CommunityOwnedDate       2387 non-null datetime64[ns]\n",
      "ParentId                 47100 non-null float64\n",
      "ClosedDate               1560 non-null datetime64[ns]\n",
      "OwnerDisplayName         1121 non-null object\n",
      "LastEditorDisplayName    249 non-null object\n",
      "Reputation               90584 non-null int64\n",
      "CreationDate             90584 non-null datetime64[ns]\n",
      "DisplayName              90584 non-null object\n",
      "LastAccessDate           90584 non-null datetime64[ns]\n",
      "WebsiteUrl               32071 non-null object\n",
      "Location                 40452 non-null object\n",
      "AboutMe                  41684 non-null object\n",
      "Views                    90584 non-null int64\n",
      "UpVotes                  90584 non-null int64\n",
      "DownVotes                90584 non-null int64\n",
      "AccountId                90584 non-null int64\n",
      "Age                      26804 non-null float64\n",
      "ProfileImageUrl          24063 non-null object\n",
      "dtypes: datetime64[ns](7), float64(8), int64(9), object(10)\n",
      "memory usage: 24.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n#missing = merge.merge(posts, how=\"outer\")\\n#missing ###postId\\', \\'postId\\', \\'PostTypeId\\', \\'AcceptedAnswerId\\', \\'CreaionDate\\',\\n       \\'Score\\', \\'ViewCount\\', \\'Body\\', \\'userId\\', \\'LasActivityDate\\', \\'Title\\',\\n       \\'Tags\\', \\'AnswerCount\\', \\'CommentCount\\', \\'LastEditorUserId\\',\\n       \\'LastEditDate\\', \\'CommunityOwnedDate\\', \\'ParentId\\', \\'ClosedDate\\',\\n       \\'OwnerDisplayName\\', \\'LastEditorDisplayName '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(merge.info())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. You will need to make something with missing values.  Will you clean or filling them? Explain. \n",
    "**Remember** to check the results of your code before passing to the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Adjust the data types in order to avoid future issues. Which ones should be changed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"column\"] = data[\"column\"].astype[other one]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Identify extreme values in your merged dataframe as you have learned in class, create a dataframe called outliers with the same columns as our data set and calculate the bounds. The values of the outliers dataframe will be the values of the merged_df that fall outside that bounds. You will need to save your outliers dataframe to a csv file on your-code folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
